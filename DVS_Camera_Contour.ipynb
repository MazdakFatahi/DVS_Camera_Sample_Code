{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original input -> height, width: 720, 1280\n",
      "Down scaled input -> height, width: 180, 320\n"
     ]
    }
   ],
   "source": [
    "import cv2, copy\n",
    "import numpy as np\n",
    "from metavision_core.event_io import EventsIterator\n",
    "\n",
    "mv_iterator = EventsIterator(input_path='', delta_t=10000)# for 10 ms\n",
    "orig_height, orig_width = mv_iterator.get_size()\n",
    "print(f'Original input -> height, width: {orig_height}, {orig_width}')\n",
    "# Original input -> height, width: 720, 1280\n",
    "\n",
    "\n",
    "\n",
    "# Since managing the HD size of the input is expensive, we usually prefer to reduce the input size\n",
    "scale_down_factor = 4\n",
    "downScaled_height, downScaled_width = orig_height//scale_down_factor, orig_width//scale_down_factor\n",
    "print(f'Down scaled input -> height, width: {downScaled_height}, {downScaled_width}')\n",
    "# Down scaled input -> height, width: 180, 320\n",
    "\n",
    "N_POL = 2 # number of polarities \n",
    "\n",
    "# Define the size of the region of interest (ROI)\n",
    "ROI_WIDTH = 100\n",
    "ROI_HEIGHT = 70\n",
    "CENTER_Y, CENTER_X = downScaled_height//2, downScaled_width//2\n",
    "ROI_Y0, ROI_X0, ROI_Y1, ROI_X1 = CENTER_Y-ROI_HEIGHT//2, CENTER_X-ROI_WIDTH//2, CENTER_Y+ROI_HEIGHT//2, CENTER_X+ROI_WIDTH//2\n",
    "\n",
    "\n",
    "\n",
    "for i, evs in enumerate(mv_iterator): # to iterate over the EventsIterator object\n",
    "    \n",
    "    # to hold the events over a period of delta_t as an BGR (openCV format) frame\n",
    "    play_back_frame_downScaled = np.zeros(( downScaled_height, downScaled_width, 3), dtype=np.uint8)\n",
    "    play_back_frame_roi = np.zeros(( ROI_HEIGHT, ROI_WIDTH, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "    if (evs.size == 0):# or (i%2==0): # We can drop some iterations \n",
    "        pass\n",
    "    else:\n",
    "        #**************************** To use only positive (negative) events ****************************\n",
    "        # evs = evs[evs['p']==1]\n",
    "\n",
    "        #*************************** Use input events to create the downscaled frame ***************************\n",
    "        # Here we are creating a CTI (Constant Time Interval) pseudo-frame. Unlike tonic (https://github.com/neuromorphs/tonic), \n",
    "        # we do not count the number of events emitted by each individual pixel durring the interval.\n",
    "        # To create a CNE (Constant Number of Events) pseudo-frame, set n_events = (desired number of events per frame) \n",
    "        # when initializing the EventsIterator object.\n",
    "        \n",
    "        tmp_evs = copy.deepcopy(evs)\n",
    "\n",
    "        # Downscaling the event spatially\n",
    "        tmp_evs['x'] = tmp_evs['x']//scale_down_factor\n",
    "        tmp_evs['y'] = tmp_evs['y']//scale_down_factor\n",
    "\n",
    "        play_back_frame_downScaled[ tmp_evs[tmp_evs['p']==0]['y'], tmp_evs[tmp_evs['p']==0]['x'], 0] = 255 # put the negative events in B channel\n",
    "        play_back_frame_downScaled[ tmp_evs[tmp_evs['p']==1]['y'], tmp_evs[tmp_evs['p']==1]['x'], 1] = 255 # put the positive events in G channel                                                                                                               # let the R channel as zero\n",
    "\n",
    "        cv2.rectangle(play_back_frame_downScaled, (ROI_X0, ROI_Y0), (ROI_X1, ROI_Y1), (0, 0, 255),2)# For multi-box\n",
    "        #**************************** Cropping the defined ROI over the downscaled events ****************************\n",
    "        tmp_evs = tmp_evs[ ( (ROI_Y0<=tmp_evs['y'])&(tmp_evs['y']<ROI_Y1) ) & ( (ROI_X0<=tmp_evs['x'])&(tmp_evs['x']<ROI_X1) ) ]\n",
    "        # Re-coordinate the events\n",
    "        tmp_evs['y']-=ROI_Y0\n",
    "        tmp_evs['x']-=ROI_X0\n",
    "        play_back_frame_roi[ tmp_evs[tmp_evs['p']==0]['y'], tmp_evs[tmp_evs['p']==0]['x'], 0] = 255\n",
    "        play_back_frame_roi[ tmp_evs[tmp_evs['p']==1]['y'], tmp_evs[tmp_evs['p']==1]['x'], 1] = 255\n",
    "\n",
    "\n",
    "        cv2.imshow(f'Camera: Scale {scale_down_factor}:1',cv2.resize(play_back_frame_downScaled, (720, 400)))\n",
    "        # cv2.imshow(f'Camera: Cropepd -> Scale  {scale_down_factor}:1',cv2.resize(play_back_frame_roi, (720, 400)))\n",
    "\n",
    "\n",
    "        # Once the frames are available, we can apply image processing to perform various tasks\n",
    "        # Here, we are detecting the contours of a certain size.\n",
    "        # Detecting contours in the downscaled frames\n",
    "        gray_image = cv2.cvtColor(play_back_frame_downScaled, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresholded_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Define the desired size of contours \n",
    "        max_contour_area_to_detect = (gray_image.shape[0]*gray_image.shape[1])//2\n",
    "        min_contour_area_to_detect = (gray_image.shape[0]*gray_image.shape[1])//7\n",
    "\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            x_min, y_min = float('inf'), float('inf')\n",
    "            x_max, y_max = float('-inf'), float('-inf')\n",
    "            \n",
    "            for i, contour in enumerate(contours):\n",
    "                contour_area = cv2.contourArea(contour)\n",
    "                if (contour_area>min_contour_area_to_detect) and (contour_area<max_contour_area_to_detect):\n",
    "\n",
    "                    # Get the bounding box for each contour\n",
    "                    x, y, w, h = cv2.boundingRect(contour)                \n",
    "                    # Update the extreme points\n",
    "                    x_min = min(x_min, x)\n",
    "                    y_min = min(y_min, y)\n",
    "                    x_max = max(x_max, x + w)\n",
    "                    y_max = max(y_max, y + h)\n",
    "                    cv2.rectangle(play_back_frame_downScaled, (x_min, y_min), (x_max, y_max), (0, 255, 255),2)# For multi-box\n",
    "            # # For single box\n",
    "            # if (contour_area>min_contour_area_to_detect) and (contour_area<max_contour_area_to_detect):\n",
    "            #     cv2.rectangle(play_back_frame_downScaled, (x_min, y_min), (x_max, y_max), (0, 255, 255), 2)\n",
    "        # Display the image with the rectangle with or without a contoursssss\n",
    "            cv2.imshow(f'Camera: Scale {scale_down_factor}:1 --> Bounding Boxs', cv2.resize(play_back_frame_downScaled,  (720, 400)))\n",
    "        \n",
    "        # Detecting contours in the ROI\n",
    "        gray_image = cv2.cvtColor(play_back_frame_roi, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresholded_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Define the desired size of contours \n",
    "        max_contour_area_to_detect = (gray_image.shape[0]*gray_image.shape[1])//2\n",
    "        min_contour_area_to_detect = (gray_image.shape[0]*gray_image.shape[1])//7\n",
    "\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            x_min, y_min = float('inf'), float('inf')\n",
    "            x_max, y_max = float('-inf'), float('-inf')\n",
    "            \n",
    "            for i, contour in enumerate(contours):\n",
    "                contour_area = cv2.contourArea(contour)\n",
    "                if (contour_area>min_contour_area_to_detect) and (contour_area<max_contour_area_to_detect):\n",
    "\n",
    "                    # Get the bounding box for each contour\n",
    "                    x, y, w, h = cv2.boundingRect(contour)                \n",
    "                    # Update the extreme points\n",
    "                    x_min = min(x_min, x)\n",
    "                    y_min = min(y_min, y)\n",
    "                    x_max = max(x_max, x + w)\n",
    "                    y_max = max(y_max, y + h)\n",
    "                    cv2.rectangle(play_back_frame_roi, (x_min, y_min), (x_max, y_max), (255, 255, 255),1)# For multi-box\n",
    "            # # For single box\n",
    "            # if (contour_area>min_contour_area_to_detect) and (contour_area<max_contour_area_to_detect):\n",
    "            #     cv2.rectangle(play_back_frame_downScaled, (x_min, y_min), (x_max, y_max), (0, 255, 255), 2)\n",
    "        # Display the image with the rectangle with or without a contoursssss\n",
    "            cv2.imshow(f'Camera: Cropepd -> Scale  {scale_down_factor}:1 --> Bounding Boxs', cv2.resize(play_back_frame_roi,  (720, 400)))\n",
    "\n",
    "\n",
    "\n",
    "        cv2.waitKey(1)  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snnToolBox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20a24a3a4007955ef5ee2dc9fb7716c1a03a2c0fc0e1cbee0d7177cafa6993b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
